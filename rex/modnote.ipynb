{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# National Oceanic and Atmospheric Administration (NOAA)\n",
    "This jupyter notebook is meant to be used along with the North American Mesoscale Forecast System (NAM) dataset.  \n",
    "This dataset can be found online under \"Data Access > Model > Datasets > NAM\" on the NOAA website.  \n",
    "Once the data has been properly requested, confirmed, and processed using NOAA's Order Data feature,  \n",
    "the requester is given 5 days to download the data via a email-link.  \n",
    "\n",
    "# NAM 2017\n",
    "To be more specific, the range this notebook will be targetting is the entire 2017 year (1800 UTC only). (100 ish Gb)  \n",
    "Through further observation of the email-link provided by NOAA, it can be seen that the files end in an extension \".tar\". These are all just zipped files. BEWARE- unpacking all these files doubles the 100Gb to 200Gb.  \n",
    "It is recommended to make a main folder (moddata) with subfolders with each month on them (01, 02, 03, ..., 12).  \n",
    "Then, putting all the corresponding \".tar\" files in their respective month folder. The idea is to unpack an entire month and then delete the \".tar\" files for that month. That way you don't have to unpack 100Gb to 200Gb and then try to delete 100Gb. It will be more like unpacking 6Gb to 12Gb then deleting the old 6Gb.\n",
    "\n",
    "# Unpacking \".tar\" Files\n",
    "The \".tar\" file names should look like the following:\n",
    "\n",
    "namanl_218_2017010118.g2.tar\n",
    "\n",
    "The format is very simple: namanl_218_yyyymmddhh.g2.tar  \n",
    "Where yyyy = year, mm = month, dd = day, hh = hour (UTC)  \n",
    "The above file would then be of 2017 January 1st 18 UTC\n",
    "\n",
    "Since this data ranges accross the entire North America continent, 18 UTC was chosen. In New York, 18 UTC translates to 2 P.M. This makes any \"real images\" from the dataset appear more visually appealing since that part of the Earth will be facing towards the sun. This would be better than \"real images\" of NA taken at night. This also saves a lot of space. Imagine simply having 2 timestamps per day instead of 1, this would easily double the size of the data. NOAA allows 4 timestamps per day (0 UTC, 6 UTC, 12 UTC, and 18 UTC).  \n",
    "\n",
    "Once you're inside the month directory containing all the \".tar\" files for that month, simply use the following command to unpack:\n",
    "\n",
    "// assuming path /moddata/01 being the path to all of january's \".tar\" files type  \n",
    "// and that you are currently inside the /01 directory, type the following into the kernel:  \n",
    "for f in *.tar; do tar -xvf $f; done\n",
    "\n",
    "This command should run for about 20 seconds and you should see all the files being unpacked individually.  \n",
    "For every \".tar\" file unpacked, there should be 5 \".grb2\" files\n",
    "\n",
    "// now type the following command to delete all of the \".tar\" files in that directory:  \n",
    "rm -r *.tar\n",
    "\n",
    "This is done for all 12 months until every subdirectory of /moddata contains only \".grb2\" files.  \n",
    "The new file format should be:\n",
    "\n",
    "nam_218_20170101_1800_000.grb2\n",
    "\n",
    "nam_218_yyyymmdd_hhhh_band.grb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "Once all of the \".grb2\" for every month are neatly organized in their own folder, the Exploritory Data Analysis can begin!  \n",
    "These files can be viewed using a python package called \"pygrib\".  \n",
    "Currently, pygrib is not available on windows (or at-least too hard to install), so the following commands and codes were performed on a Virtual Machine running Ubuntu 16.04 LTS with Anaconda2-Python 2.7 installed. Details on how to create your own Virtual Machine and install a Linux distribution can be found online. Once it's set up and working, simply go on a web-browser, on the virtual machine, and google \"Anaconda Python\", follow the instructions to install Anaconda2-Python 2.7 for Linux.  \n",
    "\n",
    "// to ensure everything downloaded correctly, go on any terminal and type in\n",
    "python -V\n",
    "\n",
    "This should return \"Python 2.7.14 :: Anaconda, Inc\" or a newer version.  \n",
    "Now to install the pygrib package using anaconda. Type the following into a terminal:\n",
    "\n",
    "conda install -c conda-forge pygrib\n",
    "\n",
    "That's about it for installations. Now let's dive into the code--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib # used to view \".grb2\" files\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grbs(grbs):\n",
    "    \"\"\"\n",
    "    grbs = pygrib.open(\"filepath.grb2\")\n",
    "    \"\"\"\n",
    "    for grb in grbs:\n",
    "        print(grb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_year(filepath):\n",
    "    \"\"\"\n",
    "    filepath: a string that includes the filepath to the folder containing all the months\n",
    "    Example: filepath = \"/mnt/moddata\" , output = {\"/mnt/moddata/01/nam_218_20170101_1800_000.grb2\", ...} \n",
    "    for all filepaths of the year 2017\n",
    "    \"\"\"\n",
    "    subfolders = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "    month_days = [\"31\", \"28\", \"31\", \"30\", \"31\", \"30\", \"31\", \"31\", \"30\", \"31\", \"30\", \"31\"]\n",
    "    bands = [\"0\", \"1\", \"2\", \"3\", \"6\"]\n",
    "    lst = [] # an empty list\n",
    "    \n",
    "    for i in range(len(subfolders)):\n",
    "        for j in range(1,int(month_days[i])):\n",
    "            for k in range(len(bands)):\n",
    "                if (j <= 9): \n",
    "                    lst.append(filepath + \"/\" + subfolders[i] + \"/nam_218_2017\" + subfolders[i] + \"0\" + str(j) +\"_1800_00\" + bands[k] + \".grb2\")\n",
    "                elif (j > 9 and j <= 19): \n",
    "                    lst.append(filepath + \"/\" +subfolders[i] + \"/nam_218_2017\" + subfolders[i] + str(j) +\"_1800_00\" + bands[k] + \".grb2\")\n",
    "                elif (j > 19 and j <= 29): \n",
    "                    lst.append(filepath + \"/\" +subfolders[i] + \"/nam_218_2017\" + subfolders[i] + str(j) +\"_1800_00\" + bands[k] + \".grb2\")     \n",
    "                else:\n",
    "                    lst.append(filepath + \"/\" +subfolders[i] + \"/nam_218_2017\" + subfolders[i] + str(j) +\"_1800_00\" + bands[k] + \".grb2\")\n",
    "                \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/moddata\" # this is the path to the directory containing all the subdirectories 01, 02, 03, 04, etc\n",
    "paths = list_year(path) # this function returns a list of all filepaths starting from the path above\n",
    "print(paths[0]) # should print the filepath for 2017 January 1st Band 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's view the very first data file \n",
    "jan_01_0 = paths[0] # path to january 1st band 0\n",
    "grbs = pygrib.open(jan_01_0)\n",
    "print(type(grbs)) # this should print <type 'pygrib.open'> if successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look inside this file\n",
    "# print_grbs(grbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by looking at the data above, the unit for temperature is kelvin (K)\n",
    "# there are multiple ways to extract data from a given \"row\"\n",
    "# .values is a numpy command used to return a numpy array\n",
    "temp_surf = grbs.select(name=\"Temperature\")[0].values # temperature at the surface\n",
    "temp_2m = grbs.select(name=\"2 metre temperature\")[0].values # temperature at 2m\n",
    "temp_5000 = grbs[58].values # index 58 is temperature at 5000m\n",
    "snow_depth = grbs[364].values # index 364 is snow depth\n",
    "soil_temp = grbs.select(name=\"Soil Temperature\")[0].values\n",
    "lightning = grbs.select(name=\"Lightning\")[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's just see what all these array's look like\n",
    "print(temp_surf)\n",
    "#print(temp_2m)\n",
    "#print(temp_5000)\n",
    "#print(snow_depth)\n",
    "#print(soil_temp)\n",
    "#print(lightning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try printing some of this data\n",
    "# this should print out a heatmap in the shape of NA. As the altitude increases the temperature decreases\n",
    "ax = sns.heatmap(temp_surf, cbar='true')\n",
    "ax.invert_yaxis() # heatmap would print it upside down if it wasn't for this\n",
    "print(np.max(temp_surf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(temp_2m, cbar='true')\n",
    "ax.invert_yaxis()\n",
    "print(np.max(temp_2m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(temp_5000, cbar='true')\n",
    "ax.invert_yaxis()\n",
    "print(np.max(temp_5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(snow_depth, cbar='true')\n",
    "ax.invert_yaxis()\n",
    "print(np.max(snow_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(lightning, cbar='true')\n",
    "ax.invert_yaxis()\n",
    "print(np.max(lightning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
